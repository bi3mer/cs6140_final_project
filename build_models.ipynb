{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime \n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = pd.read_csv('vids.csv')\n",
    "vids = vids.dropna()\n",
    "X = vids[vids.category_id.notna()]\n",
    "X = X.drop(([\n",
    "     'video_id', 'channel_title', 'trending_date', 'comments_disabled',\n",
    "     'comment_count', 'likes', 'dislikes', 'video_error_or_removed', 'thumbnail_link',\n",
    "     'ratings_disabled']), 1)\n",
    "Y = vids.views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy encode categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cateogries = pd.get_dummies(X.category_id, prefix=\"category_id\")\n",
    "X = X.drop(['category_id'], 1)\n",
    "for column in encoded_cateogries.columns:\n",
    "    X[column] = encoded_cateogries[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Publish Date to Publish Day and Encode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_time_to_day(day_string):\n",
    "    try:\n",
    "        split = day_string.split('T')[0].split('-')\n",
    "        return datetime.datetime(int(split[0]), int(split[1]), int(split[2])).strftime('%A')\n",
    "    except:\n",
    "        return 'Monday'\n",
    "\n",
    "X['publish_day'] = X.publish_time.apply(publish_time_to_day)\n",
    "encoded_cateogries = pd.get_dummies(X.publish_day, prefix=\"publish_day\")\n",
    "for column in encoded_cateogries.columns:\n",
    "    X[column] = encoded_cateogries[column]\n",
    "X = X.drop(['publish_time', 'publish_day'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode words with w2v model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265f03142d3149f08cf71e6890e165fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40291.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_titles = []\n",
    "processed_descriptions = []\n",
    "processed_tags = []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    try:\n",
    "        processed_titles.append(simple_preprocess(X.title.iloc[i]))\n",
    "    except:\n",
    "        processed_titles.append([\"\"])\n",
    "\n",
    "    try:\n",
    "        processed_descriptions.append(simple_preprocess(X.description.iloc[i]))\n",
    "    except:\n",
    "        processed_descriptions.append([\"\"])\n",
    "\n",
    "    try:\n",
    "        processed_tags.append(simple_preprocess(X.tags.iloc[i]))\n",
    "    except:\n",
    "        processed_tags.append([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f585dc36038b4ed297617540ae3bb514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40291.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(os.path.join('mdl', 'word2vec.model'))\n",
    "all_one_feature = []\n",
    "dscription_feature = []\n",
    "title_feature = []\n",
    "tags_feature = []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    filtered = [word for word in processed_titles[i] if word in w2v_model.wv.vocab]\n",
    "    if len(filtered) > 0:\n",
    "        title_vec = np.mean(w2v_model.wv[filtered], axis=0)\n",
    "    else:\n",
    "        title_vec = np.zeros(w2v_model.vector_size)\n",
    "        \n",
    "    filtered = [word for word in processed_descriptions[i] if word in w2v_model.wv.vocab]\n",
    "    if len(filtered) > 0:\n",
    "        description_vec = np.mean(w2v_model.wv[filtered], axis=0)\n",
    "    else:\n",
    "        description_vec = np.zeros(w2v_model.vector_size)\n",
    "        \n",
    "    filtered = [word for word in processed_tags[i] if word in w2v_model.wv.vocab]\n",
    "    if len(filtered) > 0:\n",
    "        tags_vec = np.mean(w2v_model.wv[filtered], axis=0)\n",
    "    else:\n",
    "        tags_vec = np.zeros(w2v_model.vector_size)\n",
    "    \n",
    "    all_one_feature.append(np.mean([title_vec, description_vec, tags_vec], axis=0))\n",
    "    dscription_feature.append(description_vec)\n",
    "    title_feature.append(title_vec)\n",
    "    tags_feature.append(tags_vec)\n",
    "\n",
    "all_one_feature = np.array(all_one_feature)\n",
    "dscription_feature = np.array(dscription_feature)\n",
    "title_feature = np.array(title_feature)\n",
    "tags_feature = np.array(tags_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b63144f814e04860f90db637cb616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(['title', 'tags', 'description'], 1)\n",
    "\n",
    "for i in tqdm(range(w2v_model.vector_size)):\n",
    "    X[f'word_encodings{i}'] = all_one_feature[:,i]\n",
    "    X[f'description{i}'] = dscription_feature[:, i]\n",
    "    X[f'title{i}'] = title_feature[:,i]\n",
    "    X[f'tags{i}'] = tags_feature[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna()\n",
    "train, test = train_test_split(X, test_size=0.2)\n",
    "\n",
    "train_y = train.views\n",
    "train_x = train.drop('views', 1)\n",
    "test_y = test.views\n",
    "test_x = test.drop('views', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = np.array([[f'title{i}', f'tags{i}', f'description{i}'] for i in range(w2v_model.vector_size)]).flatten()\n",
    "train_x_all = train_x.drop(to_drop,1)\n",
    "test_x_all = test_x.drop(to_drop,1)\n",
    "\n",
    "to_drop = [f'word_encodings{i}' for i in range(w2v_model.vector_size)]\n",
    "train_x_sep = train_x.drop(to_drop,1)\n",
    "test_x_sep = test_x.drop(to_drop,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store Train/Test Split**\n",
    "\n",
    "We may use it for some future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('data')):\n",
    "    os.mkdir(os.path.join('data'))\n",
    "    \n",
    "train_x_all.to_csv(os.path.join('data','train_x_all.csv'), index=False)\n",
    "train_x_sep.to_csv(os.path.join('data','train_x_sep.csv'), index=False)\n",
    "\n",
    "test_x_all.to_csv(os.path.join('data','test_x_all.csv'), index=False)\n",
    "test_x_sep.to_csv(os.path.join('data','test_x_sep.csv'), index=False)\n",
    "\n",
    "train_y.to_csv(os.path.join('data','train_y.csv'), index=False)\n",
    "test_y.to_csv(os.path.join('data','test_y.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_network(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_layer_network(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(int(input_dim/4), input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(int(input_dim/8), input_dim=int(input_dim/4), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(int(input_dim/16), input_dim=int(input_dim/8), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(int(input_dim/32), input_dim=int(input_dim/16), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "lr_all = LinearRegression()\n",
    "lr_sep = LinearRegression()\n",
    "\n",
    "svr_all = LinearSVR(C=1.0, epsilon=0.2)\n",
    "svr_sep = LinearSVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "rfr_all = RandomForestRegressor(n_estimators=20, max_depth=3)\n",
    "rfr_sep = RandomForestRegressor(n_estimators=20, max_depth=3)\n",
    "\n",
    "xgb_all = XGBRegressor(n_estimators=300)\n",
    "xgb_sep = XGBRegressor(n_estimators=300)\n",
    "\n",
    "gbm_all = lgbm.LGBMRegressor()\n",
    "gbm_sep = lgbm.LGBMRegressor()\n",
    "\n",
    "nn1_all = single_layer_network(train_x_all.shape[1])\n",
    "nn1_sep = single_layer_network(train_x_sep.shape[1])\n",
    "\n",
    "nn5_all = five_layer_network(train_x_all.shape[1])\n",
    "nn5_sep = five_layer_network(train_x_sep.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lr_all\n",
      "training lr_sep\n",
      "training svr_all\n",
      "training svr_sep\n",
      "training rfr_all\n",
      "training rfr_sep\n",
      "training xgb_all\n",
      "training xgb_sep\n",
      "training lgbm_all\n",
      "training lgbm_sep\n",
      "training nn1_all\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "32232/32232 [==============================] - 3s 104us/step - loss: 61611376799732.8203\n",
      "Epoch 2/50\n",
      "32232/32232 [==============================] - 3s 91us/step - loss: 61417170265521.8516\n",
      "Epoch 3/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 61085405677309.2656\n",
      "Epoch 4/50\n",
      "32232/32232 [==============================] - 3s 98us/step - loss: 60665985086563.3750\n",
      "Epoch 5/50\n",
      "32232/32232 [==============================] - 3s 93us/step - loss: 60192220496754.4375\n",
      "Epoch 6/50\n",
      "32232/32232 [==============================] - 3s 97us/step - loss: 59691728231563.5312\n",
      "Epoch 7/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 59183032958943.4688\n",
      "Epoch 8/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 58684859661526.7656\n",
      "Epoch 9/50\n",
      "32232/32232 [==============================] - 3s 98us/step - loss: 58223562502600.4609\n",
      "Epoch 10/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 57809677954568.7656\n",
      "Epoch 11/50\n",
      "32232/32232 [==============================] - 3s 98us/step - loss: 57450059156120.3672\n",
      "Epoch 12/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 57151300887937.0469\n",
      "Epoch 13/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 56914808651113.1562\n",
      "Epoch 14/50\n",
      "32232/32232 [==============================] - 3s 97us/step - loss: 56729120385820.5312\n",
      "Epoch 15/50\n",
      "32232/32232 [==============================] - 3s 91us/step - loss: 56589162476370.9219\n",
      "Epoch 16/50\n",
      "32232/32232 [==============================] - 3s 99us/step - loss: 56485488251318.1719\n",
      "Epoch 17/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 56405007912658.0625\n",
      "Epoch 18/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 56341590438145.2031\n",
      "Epoch 19/50\n",
      "32232/32232 [==============================] - 3s 96us/step - loss: 56290577724678.0312\n",
      "Epoch 20/50\n",
      "32232/32232 [==============================] - 3s 97us/step - loss: 56246370862576.8828\n",
      "Epoch 21/50\n",
      "32232/32232 [==============================] - 3s 105us/step - loss: 56206477865302.6094\n",
      "Epoch 22/50\n",
      "32232/32232 [==============================] - 3s 94us/step - loss: 56169310924760.3516\n",
      "Epoch 23/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 56133359358626.0234\n",
      "Epoch 24/50\n",
      "32232/32232 [==============================] - 3s 94us/step - loss: 56097720799064.2578\n",
      "Epoch 25/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 56062860995023.0703\n",
      "Epoch 26/50\n",
      "32232/32232 [==============================] - 3s 94us/step - loss: 56027673591141.0859\n",
      "Epoch 27/50\n",
      "32232/32232 [==============================] - 3s 101us/step - loss: 55992102199521.6875\n",
      "Epoch 28/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 55956317346561.0781\n",
      "Epoch 29/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 55920568912747.8203\n",
      "Epoch 30/50\n",
      "32232/32232 [==============================] - 3s 101us/step - loss: 55883912406523.0469\n",
      "Epoch 31/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 55846837248392.4141\n",
      "Epoch 32/50\n",
      "32232/32232 [==============================] - 3s 101us/step - loss: 55809508619851.3516\n",
      "Epoch 33/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 55771645223536.2109\n",
      "Epoch 34/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 55733053937721.4375\n",
      "Epoch 35/50\n",
      "32232/32232 [==============================] - 3s 91us/step - loss: 55694165813027.8984\n",
      "Epoch 36/50\n",
      "32232/32232 [==============================] - 3s 93us/step - loss: 55655327795315.3906\n",
      "Epoch 37/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 55615303506839.5469\n",
      "Epoch 38/50\n",
      "32232/32232 [==============================] - 3s 94us/step - loss: 55574513174842.6484\n",
      "Epoch 39/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 55533953634449.3828\n",
      "Epoch 40/50\n",
      "32232/32232 [==============================] - 3s 94us/step - loss: 55492266679403.0000\n",
      "Epoch 41/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 55450528254213.7812\n",
      "Epoch 42/50\n",
      "32232/32232 [==============================] - 3s 95us/step - loss: 55408210340876.4531\n",
      "Epoch 43/50\n",
      "32232/32232 [==============================] - 3s 103us/step - loss: 55365587198230.5625\n",
      "Epoch 44/50\n",
      "32232/32232 [==============================] - 3s 99us/step - loss: 55321809436773.6641\n",
      "Epoch 45/50\n",
      "32232/32232 [==============================] - 3s 105us/step - loss: 55277101789973.9219\n",
      "Epoch 46/50\n",
      "32232/32232 [==============================] - 3s 100us/step - loss: 55231540785010.6953\n",
      "Epoch 47/50\n",
      "32232/32232 [==============================] - 3s 99us/step - loss: 55185670176206.8203\n",
      "Epoch 48/50\n",
      "32232/32232 [==============================] - 3s 91us/step - loss: 55138951927739.3750\n",
      "Epoch 49/50\n",
      "32232/32232 [==============================] - 3s 92us/step - loss: 55092412759083.9688\n",
      "Epoch 50/50\n",
      "32232/32232 [==============================] - 3s 99us/step - loss: 55045544865886.5469\n",
      "training nn1_sep\n",
      "Epoch 1/50\n",
      "32232/32232 [==============================] - 6s 190us/step - loss: 61520852132179.5547\n",
      "Epoch 2/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 60887250471246.9766\n",
      "Epoch 3/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 59923262438391.1094\n",
      "Epoch 4/50\n",
      "32232/32232 [==============================] - 6s 192us/step - loss: 58867728739934.1641\n",
      "Epoch 5/50\n",
      "32232/32232 [==============================] - 6s 192us/step - loss: 57906216255418.8672\n",
      "Epoch 6/50\n",
      "32232/32232 [==============================] - 6s 188us/step - loss: 57116734911013.9922\n",
      "Epoch 7/50\n",
      "32232/32232 [==============================] - 6s 191us/step - loss: 56523456670821.9141\n",
      "Epoch 8/50\n",
      "32232/32232 [==============================] - 6s 179us/step - loss: 56114825521212.4922\n",
      "Epoch 9/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 55822184006677.1016\n",
      "Epoch 10/50\n",
      "32232/32232 [==============================] - 6s 184us/step - loss: 55595032212176.7969\n",
      "Epoch 11/50\n",
      "32232/32232 [==============================] - 6s 173us/step - loss: 55402626142882.0234\n",
      "Epoch 12/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 55225134434138.7969\n",
      "Epoch 13/50\n",
      "32232/32232 [==============================] - 6s 191us/step - loss: 55051108235632.5312\n",
      "Epoch 14/50\n",
      "32232/32232 [==============================] - 6s 192us/step - loss: 54875401885440.3203\n",
      "Epoch 15/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 54697499427629.2969\n",
      "Epoch 16/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 54514355878695.7109\n",
      "Epoch 17/50\n",
      "32232/32232 [==============================] - 6s 194us/step - loss: 54329454702649.9531\n",
      "Epoch 18/50\n",
      "32232/32232 [==============================] - 6s 197us/step - loss: 54142250236638.5156\n",
      "Epoch 19/50\n",
      "32232/32232 [==============================] - 6s 198us/step - loss: 53955436023404.3984\n",
      "Epoch 20/50\n",
      "32232/32232 [==============================] - 6s 196us/step - loss: 53767769969045.6406\n",
      "Epoch 21/50\n",
      "32232/32232 [==============================] - 6s 195us/step - loss: 53578413688772.5234\n",
      "Epoch 22/50\n",
      "32232/32232 [==============================] - 7s 202us/step - loss: 53389285554459.1328\n",
      "Epoch 23/50\n",
      "32232/32232 [==============================] - 6s 190us/step - loss: 53203969521381.8828\n",
      "Epoch 24/50\n",
      "32232/32232 [==============================] - 6s 175us/step - loss: 53020609547233.7578\n",
      "Epoch 25/50\n",
      "32232/32232 [==============================] - 6s 184us/step - loss: 52838886528333.1953\n",
      "Epoch 26/50\n",
      "32232/32232 [==============================] - 6s 190us/step - loss: 52661417594496.7344\n",
      "Epoch 27/50\n",
      "32232/32232 [==============================] - 6s 183us/step - loss: 52486788969298.9219\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32232/32232 [==============================] - 6s 178us/step - loss: 52315603843871.5781\n",
      "Epoch 29/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 52150365442982.2812\n",
      "Epoch 30/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 51991376714980.9922\n",
      "Epoch 31/50\n",
      "32232/32232 [==============================] - 6s 179us/step - loss: 51836118092318.3750\n",
      "Epoch 32/50\n",
      "32232/32232 [==============================] - 6s 184us/step - loss: 51686358505204.1172\n",
      "Epoch 33/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 51544208505562.4531\n",
      "Epoch 34/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 51407093922010.0703\n",
      "Epoch 35/50\n",
      "32232/32232 [==============================] - 6s 178us/step - loss: 51273913046271.9375\n",
      "Epoch 36/50\n",
      "32232/32232 [==============================] - 6s 184us/step - loss: 51145862128736.3281\n",
      "Epoch 37/50\n",
      "32232/32232 [==============================] - 6s 185us/step - loss: 51021507127014.8984\n",
      "Epoch 38/50\n",
      "32232/32232 [==============================] - 6s 189us/step - loss: 50903549305484.6719\n",
      "Epoch 39/50\n",
      "32232/32232 [==============================] - 6s 182us/step - loss: 50790914977317.2344\n",
      "Epoch 40/50\n",
      "32232/32232 [==============================] - 6s 182us/step - loss: 50682758661437.9531\n",
      "Epoch 41/50\n",
      "32232/32232 [==============================] - 6s 181us/step - loss: 50578914301155.4688\n",
      "Epoch 42/50\n",
      "32232/32232 [==============================] - 6s 171us/step - loss: 50479554621859.8672\n",
      "Epoch 43/50\n",
      "32232/32232 [==============================] - 6s 186us/step - loss: 50384431343676.4922\n",
      "Epoch 44/50\n",
      "32232/32232 [==============================] - 6s 190us/step - loss: 50292108327162.6016\n",
      "Epoch 45/50\n",
      "32232/32232 [==============================] - 6s 191us/step - loss: 50203141753040.9219\n",
      "Epoch 46/50\n",
      "32232/32232 [==============================] - 6s 178us/step - loss: 50117871963927.1953\n",
      "Epoch 47/50\n",
      "32232/32232 [==============================] - 6s 188us/step - loss: 50035905539909.9531\n",
      "Epoch 48/50\n",
      "32232/32232 [==============================] - 6s 192us/step - loss: 49957303414081.5078\n",
      "Epoch 49/50\n",
      "32232/32232 [==============================] - 6s 192us/step - loss: 49879786546845.7031\n",
      "Epoch 50/50\n",
      "32232/32232 [==============================] - 6s 180us/step - loss: 49805054170315.0703\n",
      "training nn5_all\n",
      "Epoch 1/50\n",
      "32232/32232 [==============================] - 6s 176us/step - loss: 57700361900311.5781\n",
      "Epoch 2/50\n",
      "32232/32232 [==============================] - 5s 167us/step - loss: 55219921205429.4688\n",
      "Epoch 3/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 52514614451538.7969\n",
      "Epoch 4/50\n",
      "32232/32232 [==============================] - 5s 164us/step - loss: 49334802751323.3047\n",
      "Epoch 5/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 48015027835737.0234\n",
      "Epoch 6/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 46976699316925.9844\n",
      "Epoch 7/50\n",
      "32232/32232 [==============================] - 5s 159us/step - loss: 46033168331212.5312\n",
      "Epoch 8/50\n",
      "32232/32232 [==============================] - 5s 155us/step - loss: 45190558446101.7344\n",
      "Epoch 9/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 44231585235838.6328\n",
      "Epoch 10/50\n",
      "32232/32232 [==============================] - 5s 166us/step - loss: 43342024204590.9531\n",
      "Epoch 11/50\n",
      "32232/32232 [==============================] - 5s 156us/step - loss: 42254949822700.8750\n",
      "Epoch 12/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 41160955180733.2188\n",
      "Epoch 13/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 40050504895962.0078\n",
      "Epoch 14/50\n",
      "32232/32232 [==============================] - 5s 159us/step - loss: 38817577220391.3281\n",
      "Epoch 15/50\n",
      "32232/32232 [==============================] - 5s 163us/step - loss: 37692269366445.0781\n",
      "Epoch 16/50\n",
      "32232/32232 [==============================] - 5s 158us/step - loss: 36523119772778.4922\n",
      "Epoch 17/50\n",
      "32232/32232 [==============================] - 5s 169us/step - loss: 35362229787620.8047\n",
      "Epoch 18/50\n",
      "32232/32232 [==============================] - 5s 163us/step - loss: 34208379594674.2266\n",
      "Epoch 19/50\n",
      "32232/32232 [==============================] - 5s 159us/step - loss: 33188098430813.8477\n",
      "Epoch 20/50\n",
      "32232/32232 [==============================] - 5s 168us/step - loss: 32465465046404.0977\n",
      "Epoch 21/50\n",
      "32232/32232 [==============================] - 5s 164us/step - loss: 31552818425108.7773\n",
      "Epoch 22/50\n",
      "32232/32232 [==============================] - 5s 169us/step - loss: 30720169195896.6641\n",
      "Epoch 23/50\n",
      "32232/32232 [==============================] - 5s 164us/step - loss: 30016328909869.4961\n",
      "Epoch 24/50\n",
      "32232/32232 [==============================] - 5s 169us/step - loss: 29415566351446.6641\n",
      "Epoch 25/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 28824100849571.9922\n",
      "Epoch 26/50\n",
      "32232/32232 [==============================] - 5s 167us/step - loss: 28208073037417.8594\n",
      "Epoch 27/50\n",
      "32232/32232 [==============================] - 5s 164us/step - loss: 27615762447245.3750\n",
      "Epoch 28/50\n",
      "32232/32232 [==============================] - 5s 169us/step - loss: 27084385822922.8203\n",
      "Epoch 29/50\n",
      "32232/32232 [==============================] - 5s 161us/step - loss: 26592858822493.8477\n",
      "Epoch 30/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 26059968555129.4883\n",
      "Epoch 31/50\n",
      "32232/32232 [==============================] - 5s 169us/step - loss: 25553826064172.0352\n",
      "Epoch 32/50\n",
      "32232/32232 [==============================] - 6s 172us/step - loss: 25128758723702.6914\n",
      "Epoch 33/50\n",
      "32232/32232 [==============================] - 6s 178us/step - loss: 24795115426315.5664\n",
      "Epoch 34/50\n",
      "32232/32232 [==============================] - 6s 178us/step - loss: 24431284084071.1211\n",
      "Epoch 35/50\n",
      "32232/32232 [==============================] - 5s 166us/step - loss: 23907544563557.4727\n",
      "Epoch 36/50\n",
      "32232/32232 [==============================] - 5s 161us/step - loss: 23702374720470.0625\n",
      "Epoch 37/50\n",
      "32232/32232 [==============================] - 5s 160us/step - loss: 23410110416901.5898\n",
      "Epoch 38/50\n",
      "32232/32232 [==============================] - 5s 164us/step - loss: 23100332664510.2383\n",
      "Epoch 39/50\n",
      "32232/32232 [==============================] - 5s 165us/step - loss: 22883820000125.6172\n",
      "Epoch 40/50\n",
      "32232/32232 [==============================] - 5s 161us/step - loss: 22597462749839.7266\n",
      "Epoch 41/50\n",
      "32232/32232 [==============================] - 5s 167us/step - loss: 22302312601092.1914\n",
      "Epoch 42/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 22091675359899.4180\n",
      "Epoch 43/50\n",
      "32232/32232 [==============================] - 5s 168us/step - loss: 21826352109348.9141\n",
      "Epoch 44/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 21609776566059.5273\n",
      "Epoch 45/50\n",
      "32232/32232 [==============================] - 5s 162us/step - loss: 21330943136255.3633\n",
      "Epoch 46/50\n",
      "32232/32232 [==============================] - 6s 177us/step - loss: 21104879167101.1719\n",
      "Epoch 47/50\n",
      "32232/32232 [==============================] - 5s 170us/step - loss: 20835209971127.9453\n",
      "Epoch 48/50\n",
      "32232/32232 [==============================] - 5s 161us/step - loss: 20537872741650.2344\n",
      "Epoch 49/50\n",
      "32232/32232 [==============================] - 5s 163us/step - loss: 20421675642502.8281\n",
      "Epoch 50/50\n",
      "32232/32232 [==============================] - 6s 171us/step - loss: 20261422974973.4609\n",
      "training nn5_sep\n",
      "Epoch 1/50\n",
      "32232/32232 [==============================] - 8s 261us/step - loss: 54257968382269.1875\n",
      "Epoch 2/50\n",
      "32232/32232 [==============================] - 9s 269us/step - loss: 46489313790803.4297\n",
      "Epoch 3/50\n",
      "32232/32232 [==============================] - 8s 261us/step - loss: 40358397427122.3594\n",
      "Epoch 4/50\n",
      "32232/32232 [==============================] - 8s 252us/step - loss: 34683370722799.8594\n",
      "Epoch 5/50\n",
      "32232/32232 [==============================] - 8s 254us/step - loss: 30509512796720.6719\n",
      "Epoch 6/50\n",
      "32232/32232 [==============================] - 8s 250us/step - loss: 27557293038231.3477\n",
      "Epoch 7/50\n",
      "32232/32232 [==============================] - 8s 242us/step - loss: 25393134734378.9531\n",
      "Epoch 8/50\n",
      "32232/32232 [==============================] - 8s 247us/step - loss: 23604743494990.7266\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32232/32232 [==============================] - 8s 247us/step - loss: 22034580188493.7109\n",
      "Epoch 10/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 20954878159481.8711\n",
      "Epoch 11/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 19789603087496.9922\n",
      "Epoch 12/50\n",
      "32232/32232 [==============================] - 8s 251us/step - loss: 18981632161721.3477\n",
      "Epoch 13/50\n",
      "32232/32232 [==============================] - 8s 252us/step - loss: 17999278399701.4922\n",
      "Epoch 14/50\n",
      "32232/32232 [==============================] - 8s 251us/step - loss: 17403147672528.4727\n",
      "Epoch 15/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 16825822633058.8672\n",
      "Epoch 16/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 16153962527373.1855\n",
      "Epoch 17/50\n",
      "32232/32232 [==============================] - 8s 247us/step - loss: 15756827235364.3457\n",
      "Epoch 18/50\n",
      "32232/32232 [==============================] - 8s 255us/step - loss: 15199594532220.4746\n",
      "Epoch 19/50\n",
      "32232/32232 [==============================] - 8s 257us/step - loss: 14586986293422.3516\n",
      "Epoch 20/50\n",
      "32232/32232 [==============================] - 8s 250us/step - loss: 14260347237141.9219\n",
      "Epoch 21/50\n",
      "32232/32232 [==============================] - 8s 249us/step - loss: 13542009712559.6855\n",
      "Epoch 22/50\n",
      "32232/32232 [==============================] - 8s 255us/step - loss: 13011980345272.8359\n",
      "Epoch 23/50\n",
      "32232/32232 [==============================] - 8s 251us/step - loss: 12873806185098.6426\n",
      "Epoch 24/50\n",
      "32232/32232 [==============================] - 8s 259us/step - loss: 11992791650111.8574\n",
      "Epoch 25/50\n",
      "32232/32232 [==============================] - 8s 246us/step - loss: 11731968863516.9121\n",
      "Epoch 26/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 11080151455183.3281\n",
      "Epoch 27/50\n",
      "32232/32232 [==============================] - 8s 256us/step - loss: 11068631936809.4902\n",
      "Epoch 28/50\n",
      "32232/32232 [==============================] - 8s 251us/step - loss: 10579965315317.5176\n",
      "Epoch 29/50\n",
      "32232/32232 [==============================] - 8s 250us/step - loss: 10699641676363.6113\n",
      "Epoch 30/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 10243515709153.8184\n",
      "Epoch 31/50\n",
      "32232/32232 [==============================] - 8s 250us/step - loss: 10195375545727.5234\n",
      "Epoch 32/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 10118733018487.8984\n",
      "Epoch 33/50\n",
      "32232/32232 [==============================] - 8s 244us/step - loss: 9846202358484.3496\n",
      "Epoch 34/50\n",
      "32232/32232 [==============================] - 9s 268us/step - loss: 9526288684418.0645\n",
      "Epoch 35/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 9643553437129.2285\n",
      "Epoch 36/50\n",
      "32232/32232 [==============================] - 8s 259us/step - loss: 9350596340288.9375\n",
      "Epoch 37/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 8969296933316.4004\n",
      "Epoch 38/50\n",
      "32232/32232 [==============================] - 8s 253us/step - loss: 8903520450778.0684\n",
      "Epoch 39/50\n",
      "32232/32232 [==============================] - 8s 261us/step - loss: 9233081077885.0469\n",
      "Epoch 40/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 9392399135005.6738\n",
      "Epoch 41/50\n",
      "32232/32232 [==============================] - 8s 252us/step - loss: 8907244920378.5840\n",
      "Epoch 42/50\n",
      "32232/32232 [==============================] - 8s 257us/step - loss: 8786470688581.4482\n",
      "Epoch 43/50\n",
      "32232/32232 [==============================] - 8s 244us/step - loss: 8611955388449.5488\n",
      "Epoch 44/50\n",
      "32232/32232 [==============================] - 8s 256us/step - loss: 8630900482887.7363\n",
      "Epoch 45/50\n",
      "32232/32232 [==============================] - 8s 258us/step - loss: 8345624819210.2939\n",
      "Epoch 46/50\n",
      "32232/32232 [==============================] - 8s 252us/step - loss: 8453788959752.8955\n",
      "Epoch 47/50\n",
      "32232/32232 [==============================] - 8s 251us/step - loss: 8448792780932.1621\n",
      "Epoch 48/50\n",
      "32232/32232 [==============================] - 8s 262us/step - loss: 8098946155650.8916\n",
      "Epoch 49/50\n",
      "32232/32232 [==============================] - 8s 262us/step - loss: 8514544591069.6250\n",
      "Epoch 50/50\n",
      "32232/32232 [==============================] - 8s 257us/step - loss: 8268648102158.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9700b9b8d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training lr_all')\n",
    "lr_all.fit(train_x_all, train_y)\n",
    "\n",
    "print('training lr_sep')\n",
    "lr_sep.fit(train_x_sep, train_y)\n",
    "\n",
    "print('training svr_all')\n",
    "svr_all.fit(train_x_all, train_y)\n",
    "\n",
    "print('training svr_sep')\n",
    "svr_sep.fit(train_x_sep, train_y)\n",
    "\n",
    "print('training rfr_all')\n",
    "rfr_all.fit(train_x_all, train_y)\n",
    "\n",
    "print('training rfr_sep')\n",
    "rfr_sep.fit(train_x_sep, train_y)\n",
    "\n",
    "print('training xgb_all')\n",
    "xgb_all.fit(train_x_all, train_y)\n",
    "\n",
    "print('training xgb_sep')\n",
    "xgb_sep.fit(train_x_sep, train_y)\n",
    "\n",
    "print('training lgbm_all')\n",
    "gbm_all.fit(train_x_all, train_y)\n",
    "\n",
    "print('training lgbm_sep')\n",
    "gbm_sep.fit(train_x_sep, train_y)\n",
    "\n",
    "print('training nn1_all')\n",
    "nn1_all.fit(train_x_all, train_y, epochs=50)\n",
    "\n",
    "print('training nn1_sep')\n",
    "nn1_sep.fit(train_x_sep, train_y, epochs=50)\n",
    "\n",
    "print('training nn5_all')\n",
    "nn5_all.fit(train_x_all, train_y, epochs=50)\n",
    "\n",
    "print('training nn5_sep')\n",
    "nn5_sep.fit(train_x_sep, train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr_all, open(os.path.join('mdl', 'lr_all.pkl'), 'wb'))\n",
    "pickle.dump(lr_sep, open(os.path.join('mdl', 'lr_sep.pkl'), 'wb'))\n",
    "pickle.dump(svr_all, open(os.path.join('mdl', 'svr_all.pkl'), 'wb'))\n",
    "pickle.dump(svr_sep, open(os.path.join('mdl', 'svr_sep.pkl'), 'wb'))\n",
    "pickle.dump(rfr_all, open(os.path.join('mdl', 'rfr_all.pkl'), 'wb'))\n",
    "pickle.dump(rfr_sep, open(os.path.join('mdl', 'rfr_sep.pkl'), 'wb'))\n",
    "pickle.dump(xgb_all, open(os.path.join('mdl', 'xgb_all.pkl'), 'wb'))\n",
    "pickle.dump(xgb_sep, open(os.path.join('mdl', 'xgb_sep.pkl'), 'wb'))\n",
    "pickle.dump(gbm_all, open(os.path.join('mdl', 'gbm_all.pkl'), 'wb'))\n",
    "pickle.dump(gbm_sep, open(os.path.join('mdl', 'gbm_sep.pkl'), 'wb'))\n",
    "pickle.dump(nn1_all, open(os.path.join('mdl', 'nn1_all.pkl'), 'wb'))\n",
    "pickle.dump(nn1_sep, open(os.path.join('mdl', 'nn1_sep.pkl'), 'wb'))\n",
    "pickle.dump(nn5_all, open(os.path.join('mdl', 'nn5_all.pkl'), 'wb'))\n",
    "pickle.dump(nn5_sep, open(os.path.join('mdl', 'nn5_sep.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
